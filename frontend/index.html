<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Voice Intelligence</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            max-width: 600px;
            width: 100%;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .header h1 {
            color: #333;
            margin-bottom: 10px;
        }

        .header p {
            color: #666;
            margin-bottom: 20px;
        }

        .status {
            padding: 10px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
            font-weight: bold;
        }

        .status.ready {
            background: #d4edda;
            color: #155724;
        }

        .status.listening {
            background: #fff3cd;
            color: #856404;
            animation: pulse 1.5s infinite;
        }

        .status.processing {
            background: #cce7ff;
            color: #004085;
        }

        .status.speaking {
            background: #f8d7da;
            color: #721c24;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 30px;
        }

        .btn {
            padding: 15px 25px;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .btn-primary {
            background: #007bff;
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            background: #0056b3;
        }

        .btn-secondary {
            background: #6c757d;
            color: white;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #545b62;
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .chat-area {
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 20px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 15px;
            border-radius: 15px;
            max-width: 80%;
        }

        .message.user {
            background: #007bff;
            color: white;
            margin-left: auto;
        }

        .message.assistant {
            background: #f8f9fa;
            color: #333;
            border: 1px solid #e9ecef;
        }

        .message-header {
            font-size: 12px;
            opacity: 0.7;
            margin-bottom: 5px;
        }

        .emotion-info {
            background: #e7f3ff;
            border: 1px solid #b3d7ff;
            border-radius: 10px;
            padding: 10px;
            margin-top: 10px;
            font-size: 12px;
        }

        .input-area {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }

        .text-input {
            flex: 1;
            padding: 15px;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            font-size: 16px;
        }

        .text-input:focus {
            outline: none;
            border-color: #007bff;
        }

        .audio-visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 2px;
            height: 40px;
            margin: 10px 0;
        }

        .bar {
            width: 4px;
            height: 10px;
            background: #007bff;
            border-radius: 2px;
            animation: wave 1.5s infinite ease-in-out;
        }

        .bar:nth-child(2) { animation-delay: 0.1s; }
        .bar:nth-child(3) { animation-delay: 0.2s; }
        .bar:nth-child(4) { animation-delay: 0.3s; }
        .bar:nth-child(5) { animation-delay: 0.4s; }

        @keyframes wave {
            0%, 40%, 100% { transform: scaleY(0.4); }
            20% { transform: scaleY(1); }
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Neural Voice Intelligence</h1>
            <p>An Advanced AI Voice Assistant Using Multi-Modal Emotion Detection & Contextual Understanding</p>
        </div>

        <div id="status" class="status ready">
            Ready - Click "Start Listening" to begin
        </div>

        <div class="controls">
            <button id="startBtn" class="btn btn-primary">Start Listening</button>
            <button id="stopBtn" class="btn btn-secondary" disabled>Stop Listening</button>
            <button id="clearBtn" class="btn btn-secondary">Clear Chat</button>
        </div>

        <div id="visualizer" class="audio-visualizer hidden">
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
        </div>

        <div class="input-area">
            <input type="text" id="textInput" class="text-input" placeholder="Or type your message here...">
            <button id="sendBtn" class="btn btn-primary">Send</button>
        </div>

        <div id="chatArea" class="chat-area">
            <div class="message assistant">
                <div class="message-header">Natalie</div>
                Hello! I'm Natalie, your emotionally intelligent AI assistant. I can detect and respond to your emotions with appropriate voice and empathy. How are you feeling today?
            </div>
        </div>
    </div>

    <script>
        // Configuration
        const API_BASE_URL = 'http://localhost:8000';
        
        // DOM elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const sendBtn = document.getElementById('sendBtn');
        const textInput = document.getElementById('textInput');
        const chatArea = document.getElementById('chatArea');
        const status = document.getElementById('status');
        const visualizer = document.getElementById('visualizer');
        
        // State
        let isRecording = false;
        let mediaRecorder = null;
        let audioChunks = [];
        
        // Initialize
        init();
        
        async function init() {
            try {
                const response = await fetch(`${API_BASE_URL}/health`);
                const health = await response.json();
                
                if (health.status === 'healthy') {
                    updateStatus('ready', 'Connected to Natalie API - Ready to chat');
                } else {
                    updateStatus('error', 'API connection issue');
                }
            } catch (error) {
                updateStatus('error', 'Cannot connect to Natalie API');
                console.error('API connection failed:', error);
            }
        }
        
        // Event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        clearBtn.addEventListener('click', clearChat);
        sendBtn.addEventListener('click', sendTextMessage);
        textInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendTextMessage();
            }
        });
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await processVoiceInput(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
                visualizer.classList.remove('hidden');
                updateStatus('listening', 'Listening... Speak now');
                
            } catch (error) {
                console.error('Recording failed:', error);
                updateStatus('error', 'Microphone access denied');
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                visualizer.classList.add('hidden');
                updateStatus('processing', 'Processing your speech...');
                
                // Stop all tracks to release microphone
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
        }
        
        async function processVoiceInput(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio_file', audioBlob, 'audio.wav');
                
                const response = await fetch(`${API_BASE_URL}/process_speech`, {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    const result = await response.json();
                    const transcription = result.transcription;
                    const emotionData = result.emotion_data;
                    
                    // Add user message
                    addMessage('user', transcription, emotionData);
                    
                    // Get AI response
                    await getAIResponse(transcription);
                } else {
                    throw new Error('Speech processing failed');
                }
                
            } catch (error) {
                console.error('Voice processing failed:', error);
                updateStatus('error', 'Voice processing failed');
                setTimeout(() => updateStatus('ready', 'Ready - Click "Start Listening" to try again'), 3000);
            }
        }
        
        async function sendTextMessage() {
            const text = textInput.value.trim();
            if (!text) return;
            
            textInput.value = '';
            updateStatus('processing', 'Processing your message...');
            
            try {
                // Detect emotion first
                const emotionResponse = await fetch(`${API_BASE_URL}/detect_emotion`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text })
                });
                
                const emotionData = await emotionResponse.json();
                
                // Add user message
                addMessage('user', text, emotionData);
                
                // Get AI response
                await getAIResponse(text);
                
            } catch (error) {
                console.error('Text processing failed:', error);
                updateStatus('error', 'Message processing failed');
                setTimeout(() => updateStatus('ready', 'Ready to continue chatting'), 3000);
            }
        }
        
        async function getAIResponse(userText) {
            try {
                updateStatus('processing', 'Natalie is thinking...');
                
                const response = await fetch(`${API_BASE_URL}/chat`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: userText })
                });
                
                if (response.ok) {
                    const result = await response.json();
                    
                    // Add AI message
                    addMessage('assistant', result.response_text, result.emotion_data);
                    
                    // Play audio if available
                    if (result.audio_url) {
                        updateStatus('speaking', 'Natalie is speaking...');
                        await playAudio(result.audio_url);
                    }
                    
                    updateStatus('ready', 'Ready for your next message');
                } else {
                    throw new Error('AI response failed');
                }
                
            } catch (error) {
                console.error('AI response failed:', error);
                addMessage('assistant', 'I apologize, I encountered a technical issue. Please try again.', {
                    emotion: 'neutral',
                    confidence: 1.0,
                    intensity: 'medium'
                });
                updateStatus('ready', 'Ready to continue chatting');
            }
        }
        
        async function playAudio(audioUrl) {
            try {
                const audio = new Audio(audioUrl);
                
                return new Promise((resolve, reject) => {
                    audio.onended = () => {
                        updateStatus('ready', 'Ready for your next message');
                        resolve();
                    };
                    audio.onerror = reject;
                    audio.play();
                });
                
            } catch (error) {
                console.error('Audio playback failed:', error);
                updateStatus('ready', 'Audio playback failed, but ready to continue');
            }
        }
        
        function addMessage(sender, text, emotionData = null) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            
            let emotionInfo = '';
            if (emotionData && sender === 'user') {
                emotionInfo = `
                    <div class="emotion-info">
                        Detected: ${emotionData.emotion} (${emotionData.intensity} intensity, ${(emotionData.confidence * 100).toFixed(0)}% confidence)
                    </div>
                `;
            }
            
            messageDiv.innerHTML = `
                <div class="message-header">${sender === 'user' ? 'You' : 'Natalie'}</div>
                ${text}
                ${emotionInfo}
            `;
            
            chatArea.appendChild(messageDiv);
            chatArea.scrollTop = chatArea.scrollHeight;
        }
        
        function updateStatus(type, message) {
            status.className = `status ${type}`;
            status.textContent = message;
        }
        
        function clearChat() {
            chatArea.innerHTML = `
                <div class="message assistant">
                    <div class="message-header">Natalie</div>
                    Hello! I'm Natalie, your emotionally intelligent AI assistant. How can I help you today?
                </div>
            `;
        }
    </script>
</body>
</html>
